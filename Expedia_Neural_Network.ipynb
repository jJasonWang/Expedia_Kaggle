{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv\n",
    "%matplotlib inline\n",
    "\n",
    "from average_precision import apk, mapk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "expedia_train = pd.read_csv('Data/train.csv', nrows=500000)\n",
    "\n",
    "# Pull out features\n",
    "train_cols = ['site_name', 'user_location_country', 'user_location_region', 'user_location_city',\n",
    "              'is_mobile', 'is_package', 'channel', 'srch_adults_cnt',\n",
    "              'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_id', 'srch_destination_type_id',\n",
    "              'hotel_continent','hotel_country', 'hotel_market', 'hotel_cluster']\n",
    "\n",
    "# Save ID\n",
    "user_id = expedia_train['user_id'].ravel()\n",
    "expedia_train = expedia_train[train_cols]\n",
    "X_train = expedia_train.iloc[:, :-1]\n",
    "y_train = expedia_train.iloc[:, -1]\n",
    "\n",
    "means = X_train.apply(np.mean, axis=0).ravel()\n",
    "stds = X_train.apply(np.std, axis=0).ravel()\n",
    "\n",
    "# Standardized the data\n",
    "X_norm = preprocessing.scale(X_train)\n",
    "\n",
    "# Transform y_train into a matrix form\n",
    "y = np.zeros((100, len(y_train)))\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y[:, i] = np.eye(100)[y_train[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def s(r):\n",
    "    return(1/(1 + np.exp(-r)))\n",
    "\n",
    "# tanh function\n",
    "def tanh(z):\n",
    "    return(2*s(2*z) - 1)\n",
    "\n",
    "# Risk function for mean squared error loss\n",
    "def risk_f1(X, y, V, W, x_size, h_size):\n",
    "    h = tanh((V.dot(np.insert(X, x_size, 1, axis=1).T)))\n",
    "    z = s(W.dot(np.insert(h, h_size, 1, axis=0)))\n",
    "    return(np.sum((z - y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNeuralNetwork(X, labels, epsilon, change_point, max_iter,\n",
    "                       x_size=15, h_size=50, z_size=100):\n",
    "    # Initialize weight\n",
    "    V = np.random.uniform(-1, 1, (h_size, x_size))\n",
    "    W = np.random.uniform(-1, 1, (z_size, h_size))\n",
    "    # Intercept\n",
    "    V = np.insert(V, x_size, 1, axis=1)\n",
    "    W = np.insert(W, h_size, 1, axis=1)\n",
    "    \n",
    "    i = 0\n",
    "    while i <= max_iter:\n",
    "        if i in change_point:\n",
    "            epsilon = epsilon/10\n",
    "            print(\"After \", str(i), \"th iterations\", \"\\n\" \n",
    "                  \"The learning rate changes to \",\n",
    "                  str(epsilon), sep='')\n",
    "        if i % (max_iter/10) == 0:\n",
    "            print('Finishing iteration ', str(i), '\\n',\n",
    "                  'Risk at this iteration is ',\n",
    "                  str(risk_f1(X, labels, V, W, x_size, h_size)), sep='')\n",
    "            \n",
    "        # pick one data point randomly\n",
    "        index = np.random.choice(np.arange(len(X)))\n",
    "        \n",
    "        # Forward pass\n",
    "        h = tanh(V.dot(np.insert(X[index], x_size, 1)))\n",
    "        z = s(W.dot(np.insert(h, h_size, 1)))\n",
    "        \n",
    "        # Backward pass\n",
    "        z_grad = z - labels[:, index]\n",
    "        W_grad = ((z_grad*z*(1 - z)).reshape(100, 1)*h.reshape(1, h_size))\n",
    "        h_grad = (z_grad*z*(1 - z)).reshape(1, 100).dot(W[:, :-1]).ravel()\n",
    "        V_grad = ((h_grad*(1 - h**2)).reshape(h_size, 1)*images[index])\n",
    "        \n",
    "        # stochastic gradient descent update\n",
    "        V[:, :-1] = V[:, :-1] - epsilon*V_grad\n",
    "        W[:, :-1] = W[:, :-1] - epsilon*W_grad\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return(V, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing iteration 0\n",
      "Risk at this iteration is 24824585.5736\n",
      "After 50000th iterations\n",
      "The learning rate changes to 0.01\n",
      "Finishing iteration 50000\n",
      "Risk at this iteration is 498185.753702\n",
      "Finishing iteration 100000\n",
      "Risk at this iteration is 497346.892196\n",
      "After 150000th iterations\n",
      "The learning rate changes to 0.001\n",
      "Finishing iteration 150000\n",
      "Risk at this iteration is 496470.425532\n",
      "Finishing iteration 200000\n",
      "Risk at this iteration is 496406.351742\n",
      "Finishing iteration 250000\n",
      "Risk at this iteration is 496343.37726\n",
      "After 300000th iterations\n",
      "The learning rate changes to 0.0001\n",
      "Finishing iteration 300000\n",
      "Risk at this iteration is 496294.292905\n",
      "Finishing iteration 350000\n",
      "Risk at this iteration is 496288.785152\n",
      "Finishing iteration 400000\n",
      "Risk at this iteration is 496283.863711\n",
      "Finishing iteration 450000\n",
      "Risk at this iteration is 496278.644469\n",
      "Finishing iteration 500000\n",
      "Risk at this iteration is 496274.132167\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "change_point = (50000, 150000, 300000)\n",
    "V, W = trainNeuralNetwork(X_norm, y, 0.1, change_point, 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictNeuralNetwork(V, W, X):\n",
    "    h = tanh((V.dot(np.insert(X, 15, 1, axis=1).T)))\n",
    "    z = s(W.dot(np.insert(h, 50, 1, axis=0)))\n",
    "    \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = predictNeuralNetwork(V, W, X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_5(x):\n",
    "    return(np.argsort(x)[-5:][::-1])\n",
    "\n",
    "def change_format(ls):\n",
    "    return(' '.join([str(l) for l in ls]))\n",
    "\n",
    "def pred(probs, user_id):\n",
    "    # Get the top 5 hotel\n",
    "    top5 = np.apply_along_axis(top_5, 1, probs)\n",
    "    \n",
    "    return([[id, change_format(top5[i])] for i, id in enumerate(user_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the user_hotel which can be used for evaluation\n",
    "user_hotel = pickle.load(open(\"user_hotel.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08119796833333337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation(true_dict, prediction, k=5):\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    for _, p in enumerate(prediction):\n",
    "        try:\n",
    "            true_value = true_dict[p[0]]\n",
    "        except:\n",
    "            true_value = []\n",
    "        pred = [float(h) for h in p[1].split(' ') if len(h) != 0]\n",
    "        actuals.append(true_value)\n",
    "        preds.append(pred)\n",
    "\n",
    "    return(mapk(actuals, preds, k))\n",
    "\n",
    "predictions = pred(prediction.T, user_id)\n",
    "evaluation(user_hotel, predictions, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expedia_test = pd.read_csv('Data/test.csv')\n",
    "test_id = expedia_test['id'].ravel()\n",
    "expedia_test = expedia_test[train_cols[:-1]]\n",
    "# Normalize\n",
    "expedia_test_norm = (expedia_test.as_matrix() - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictNeuralNetwork(V, W, expedia_test_norm)\n",
    "predictions = pred(predictions.T, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('prediction_NN.csv', 'w') as outfile:\n",
    "    csv_out = csv.writer(outfile)\n",
    "    csv_out.writerow(['id', 'hotel_cluster'])\n",
    "    for i, cluster in enumerate(predictions):\n",
    "        csv_out.writerow([i, cluster])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
